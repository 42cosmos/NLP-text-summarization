{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = './chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numdays = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_list = [str(i) for i in range(100,106)]\n",
    "news_number_list = [str(i) for i in range(1,31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = datetime.datetime.today()\n",
    "date_list = [(base - datetime.timedelta(days=x)).strftime('%Y%m%d') for x in range(numdays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_news_data(category_id):\n",
    "    data_list = []\n",
    "    driver = webdriver.Chrome(web)\n",
    "    for date_string in date_list:\n",
    "        for number in news_number_list:\n",
    "            _url = \"https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=\"+category_id+\"&date=\"+date_string\n",
    "            driver.get(_url)\n",
    "\n",
    "            driver.find_element_by_xpath('//*[@id=\"wrap\"]/table/tbody/tr/td[2]/div/div[4]/ol/li['+number+']/div/div[1]/a').click()\n",
    "            title = driver.find_element_by_xpath('//*[@id=\"articleTitle\"]').text\n",
    "            date = driver.find_element_by_xpath('//*[@id=\"main_content\"]/div[1]/div[3]/div/span[1]').text\n",
    "            contents = driver.find_element_by_xpath('//*[@id=\"articleBodyContents\"]').text\n",
    "            current_url = driver.current_url\n",
    "            driver.find_element_by_xpath('//*[@id=\"main_content\"]/div[1]/div[3]/div/div[3]/div[2]/div[1]').click()\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                sum_bot = driver.find_element_by_xpath('//*[@id=\"main_content\"]/div[1]/div[3]/div/div[3]/div[2]/div[1]/div/div[2]/div[1]').text\n",
    "            except:\n",
    "                sum_bot = None\n",
    "                \n",
    "            df = pd.DataFrame([title, date, category_id, contents, sum_bot, current_url]).T\n",
    "            df.columns = ['title', 'date', 'category_id', 'contents', 'summarisation', 'url']\n",
    "            data_list.append(df)\n",
    "            driver.back()\n",
    "    driver.close()\n",
    "    all_data = pd.concat(data_list)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START DATE : 2020-09-17 16:38:50.384438\n",
      "END DATE : 2020-09-17 16:43:33.497394\n"
     ]
    }
   ],
   "source": [
    "num_cpu = multiprocessing.cpu_count() - 1\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "print(\"START DATE :\", start_time)\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(num_cpu)\n",
    "results = pool.imap(crawling_news_data, category_id_list)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"END DATE :\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(results)\n",
    "all_data = pd.concat(all_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('news_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
